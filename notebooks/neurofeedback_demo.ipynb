{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurofeedback Model Demo\n",
    "\n",
    "This notebook demonstrates the computational model of neurofeedback based on Davelaar (2018). We'll explore the main components of the model, run simulations, and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the path\n",
    "src_dir = Path('..') / \"src\"\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "# Import the neurofeedback model\n",
    "from neurofeedback_model import NeurofeedbackModel\n",
    "from brian2 import second, ms\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the Model\n",
    "\n",
    "The neurofeedback model consists of these key components:\n",
    "\n",
    "1. **Spiking Neuron Network**: An Izhikevich-type neural network that generates EEG-like signals\n",
    "2. **Striatal Learning Mechanism**: A reinforcement learning process that modifies the activation probabilities of striatal units\n",
    "3. **Feedback System**: Real-time analysis of the EEG signal to provide feedback\n",
    "\n",
    "According to Davelaar's theory, neurofeedback learning occurs in multiple stages, with the striatum playing a critical role in the initial exploration phase. The model implements this first stage of learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the Model\n",
    "\n",
    "Let's create an instance of the neurofeedback model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create results directory\n",
    "results_dir = Path(\"../results/notebook_demo\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set parameters\n",
    "params = {\n",
    "    'ne': 800,               # number of excitatory neurons\n",
    "    'ni': 200,               # number of inhibitory neurons\n",
    "    'n_striatum': 1000,      # number of striatal units\n",
    "    'duration': 5*second,    # simulation duration (shorter for demo)\n",
    "    'dt': 0.1*ms,            # simulation time step\n",
    "    'feedback_interval': 100*ms,  # how often to give feedback\n",
    "    'learning_rate': 0.01,   # learning rate for weights update\n",
    "    'alpha_band': (8, 12),   # alpha frequency band (Hz)\n",
    "    'threshold': 1.0,        # threshold for positive feedback\n",
    "    'seed': 42,              # random seed for reproducibility\n",
    "    'results_dir': str(results_dir)\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = NeurofeedbackModel(**params)\n",
    "\n",
    "print(f\"Model created with {model.ne} excitatory neurons and {model.ni} inhibitory neurons\")\n",
    "print(f\"Target MSN unit: {model.target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running a Baseline Simulation\n",
    "\n",
    "First, let's run a baseline simulation without neurofeedback learning to understand the natural distribution of alpha power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run baseline simulation\n",
    "baseline_results = model.simulate(baseline_run=True)\n",
    "\n",
    "# Extract results\n",
    "alpha_power_history = baseline_results['results']['alpha_power_history']\n",
    "\n",
    "# Calculate statistics\n",
    "mean_alpha = np.mean(alpha_power_history)\n",
    "std_alpha = np.std(alpha_power_history)\n",
    "min_alpha = np.min(alpha_power_history)\n",
    "max_alpha = np.max(alpha_power_history)\n",
    "\n",
    "print(f\"Baseline alpha power statistics:\")\n",
    "print(f\"Mean: {mean_alpha:.4f}\")\n",
    "print(f\"Std: {std_alpha:.4f}\")\n",
    "print(f\"Min: {min_alpha:.4f}\")\n",
    "print(f\"Max: {max_alpha:.4f}\")\n",
    "\n",
    "# Plot baseline alpha power\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alpha_power_history, label='Alpha Power')\n",
    "plt.axhline(y=mean_alpha, color='r', linestyle='--', label=f'Mean ({mean_alpha:.4f})')\n",
    "plt.xlabel('Feedback Index')\n",
    "plt.ylabel('Alpha Power')\n",
    "plt.title('Baseline Alpha Power')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram of baseline alpha power\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(alpha_power_history, kde=True)\n",
    "plt.axvline(x=mean_alpha, color='r', linestyle='--', label=f'Mean ({mean_alpha:.4f})')\n",
    "plt.xlabel('Alpha Power')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Baseline Alpha Power')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the threshold based on baseline\n",
    "\n",
    "Let's set our threshold for positive feedback based on the mean of the baseline alpha power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set threshold to mean baseline alpha power\n",
    "model.threshold = mean_alpha\n",
    "print(f\"Threshold set to {model.threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Neurofeedback Training\n",
    "\n",
    "Now, let's run the actual neurofeedback training simulation and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run neurofeedback training\n",
    "results = model.simulate()\n",
    "\n",
    "# Plot results\n",
    "model.plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing the Learning Process\n",
    "\n",
    "Let's analyze how the neurofeedback learning process unfolded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract results data\n",
    "weight_history = results['results']['weight_history']\n",
    "alpha_power_history = results['results']['alpha_power_history']\n",
    "feedback_history = results['results']['feedback_history']\n",
    "target_activation_history = results['results']['target_activation_history']\n",
    "\n",
    "# Calculate feedback window\n",
    "feedback_window = 10\n",
    "success_rate = np.convolve(feedback_history, np.ones(feedback_window)/feedback_window, mode='valid')\n",
    "\n",
    "# Plot moving average of success rate\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(success_rate, label=f'Success Rate (MA-{feedback_window})')\n",
    "plt.xlabel('Feedback Index')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.title('Moving Average of Positive Feedback Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot target activations vs feedback\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(target_activation_history, 'b-', label='Target MSN Active', alpha=0.5)\n",
    "plt.plot(feedback_history, 'g-', label='Positive Feedback', alpha=0.5)\n",
    "plt.xlabel('Feedback Index')\n",
    "plt.ylabel('Status (0=False, 1=True)')\n",
    "plt.title('Target MSN Activation vs Positive Feedback')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation between target activation and feedback\n",
    "correlation = np.corrcoef(target_activation_history, feedback_history)[0, 1]\n",
    "print(f\"Correlation between target activation and positive feedback: {correlation:.4f}\")\n",
    "\n",
    "# Calculate the final success metrics\n",
    "final_target_weight = weight_history[-1]\n",
    "final_alpha_power = alpha_power_history[-1]\n",
    "overall_success_rate = sum(feedback_history) / len(feedback_history)\n",
    "\n",
    "print(f\"Final target MSN weight: {final_target_weight:.4f}\")\n",
    "print(f\"Final alpha power: {final_alpha_power:.4f}\")\n",
    "print(f\"Overall success rate: {overall_success_rate:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Alpha Power Distributions\n",
    "\n",
    "Let's compare the distribution of alpha power before and after neurofeedback training to see how it changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get baseline and training alpha power\n",
    "baseline_alpha = baseline_results['results']['alpha_power_history']\n",
    "training_alpha = results['results']['alpha_power_history']\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(baseline_alpha, label='Baseline', fill=True, alpha=0.5)\n",
    "sns.kdeplot(training_alpha, label='After Training', fill=True, alpha=0.5)\n",
    "plt.axvline(x=np.mean(baseline_alpha), color='blue', linestyle='--', \n",
    "            label=f'Baseline Mean ({np.mean(baseline_alpha):.4f})')\n",
    "plt.axvline(x=np.mean(training_alpha), color='orange', linestyle='--', \n",
    "            label=f'Training Mean ({np.mean(training_alpha):.4f})')\n",
    "plt.xlabel('Alpha Power')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Alpha Power Distribution Before and After Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate percent change\n",
    "percent_change = (np.mean(training_alpha) - np.mean(baseline_alpha)) / np.mean(baseline_alpha) * 100\n",
    "print(f\"Mean alpha power increased by {percent_change:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parameter Exploration\n",
    "\n",
    "Let's explore the effect of different learning rates on neurofeedback training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Try different learning rates\n",
    "learning_rates = [0.001, 0.005, 0.01, 0.02, 0.05]\n",
    "final_weights = []\n",
    "final_powers = []\n",
    "success_rates = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nRunning simulation with learning_rate = {lr}\")\n",
    "    \n",
    "    # Create a new model with this learning rate\n",
    "    params['learning_rate'] = lr\n",
    "    params['seed'] = 42  # Keep same seed for reproducibility\n",
    "    test_model = NeurofeedbackModel(**params)\n",
    "    \n",
    "    # Run simulation\n",
    "    test_results = test_model.simulate()\n",
    "    \n",
    "    # Extract metrics\n",
    "    final_target_weight = test_results['results']['weight_history'][-1]\n",
    "    final_alpha_power = test_results['results']['alpha_power_history'][-1]\n",
    "    overall_success_rate = sum(test_results['results']['feedback_history']) / len(test_results['results']['feedback_history'])\n",
    "    \n",
    "    print(f\"Final target weight: {final_target_weight:.4f}\")\n",
    "    print(f\"Final alpha power: {final_alpha_power:.4f}\")\n",
    "    print(f\"Success rate: {overall_success_rate:.2f}\")\n",
    "    \n",
    "    final_weights.append(final_target_weight)\n",
    "    final_powers.append(final_alpha_power)\n",
    "    success_rates.append(overall_success_rate)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "# Plot final weights\n",
    "axs[0].plot(learning_rates, final_weights, 'o-')\n",
    "axs[0].set_ylabel('Final Target Weight')\n",
    "axs[0].set_title('Effect of Learning Rate on Final Target Weight')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot final alpha power\n",
    "axs[1].plot(learning_rates, final_powers, 'o-')\n",
    "axs[1].set_ylabel('Final Alpha Power')\n",
    "axs[1].set_title('Effect of Learning Rate on Final Alpha Power')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot success rates\n",
    "axs[2].plot(learning_rates, success_rates, 'o-')\n",
    "axs[2].set_ylabel('Success Rate')\n",
    "axs[2].set_xlabel('Learning Rate')\n",
    "axs[2].set_title('Effect of Learning Rate on Success Rate')\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimal Threshold Setting\n",
    "\n",
    "Let's investigate the effect of different threshold settings on learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Try different threshold multipliers relative to baseline mean\n",
    "threshold_multipliers = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "thresholds = [mean_alpha * mult for mult in threshold_multipliers]\n",
    "final_weights = []\n",
    "final_powers = []\n",
    "success_rates = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\nRunning simulation with threshold = {threshold:.4f}\")\n",
    "    \n",
    "    # Create a new model with this threshold\n",
    "    params['threshold'] = threshold\n",
    "    params['learning_rate'] = 0.01  # Reset to default\n",
    "    params['seed'] = 42  # Keep same seed for reproducibility\n",
    "    test_model = NeurofeedbackModel(**params)\n",
    "    \n",
    "    # Run simulation\n",
    "    test_results = test_model.simulate()\n",
    "    \n",
    "    # Extract metrics\n",
    "    final_target_weight = test_results['results']['weight_history'][-1]\n",
    "    final_alpha_power = test_results['results']['alpha_power_history'][-1]\n",
    "    overall_success_rate = sum(test_results['results']['feedback_history']) / len(test_results['results']['feedback_history'])\n",
    "    \n",
    "    print(f\"Final target weight: {final_target_weight:.4f}\")\n",
    "    print(f\"Final alpha power: {final_alpha_power:.4f}\")\n",
    "    print(f\"Success rate: {overall_success_rate:.2f}\")\n",
    "    \n",
    "    final_weights.append(final_target_weight)\n",
    "    final_powers.append(final_alpha_power)\n",
    "    success_rates.append(overall_success_rate)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "# Plot final weights\n",
    "axs[0].plot(threshold_multipliers, final_weights, 'o-')\n",
    "axs[0].set_ylabel('Final Target Weight')\n",
    "axs[0].set_title('Effect of Threshold Multiplier on Final Target Weight')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot final alpha power\n",
    "axs[1].plot(threshold_multipliers, final_powers, 'o-')\n",
    "axs[1].set_ylabel('Final Alpha Power')\n",
    "axs[1].set_title('Effect of Threshold Multiplier on Final Alpha Power')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot success rates\n",
    "axs[2].plot(threshold_multipliers, success_rates, 'o-')\n",
    "axs[2].set_ylabel('Success Rate')\n",
    "axs[2].set_xlabel('Threshold Multiplier (relative to baseline mean)')\n",
    "axs[2].set_title('Effect of Threshold Multiplier on Success Rate')\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've explored the neurofeedback computational model based on Davelaar's theory. We have:\n",
    "\n",
    "1. Set up the model and run baseline and training simulations\n",
    "2. Analyzed the learning process and how it affects alpha power\n",
    "3. Compared alpha power distributions before and after training\n",
    "4. Explored the effects of different learning rates and thresholds on training effectiveness\n",
    "\n",
    "The model provides a computational framework for understanding the neural mechanisms of neurofeedback training, particularly the role of the striatum in the initial learning phase.\n",
    "\n",
    "Key findings from our parameter exploration:\n",
    "- Learning rate affects the speed of convergence, with an optimal value likely between 0.005 and 0.02\n",
    "- Threshold setting is critical for successful learning, with the optimal threshold typically near the mean of the baseline alpha power\n",
    "\n",
    "These insights can help guide the design of more effective neurofeedback protocols in clinical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
